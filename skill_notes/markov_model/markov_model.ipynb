{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the mat\",\n",
    "    \"the cat chased the dog\",\n",
    "    \"the dog chased the cat\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = defaultdict(list)\n",
    "for sentence in corpus:\n",
    "    \n",
    "    words = sentence.split() # split into words\n",
    "    \n",
    "    for i in range(len(words)-1):\n",
    "        bigram_model[words[i]].append(words[i + 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'the': ['cat', 'mat', 'dog', 'mat', 'cat', 'dog', 'dog', 'cat'],\n",
       "             'cat': ['sat', 'chased'],\n",
       "             'sat': ['on', 'on'],\n",
       "             'on': ['the', 'the'],\n",
       "             'dog': ['sat', 'chased'],\n",
       "             'chased': ['the', 'the']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the all possible next words for each word in whole corpus\n",
    "bigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat chased the cat chased the mat\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(start_word, max_length=10):\n",
    "    current_word = start_word\n",
    "    sentence = [current_word]\n",
    "    \n",
    "    for _ in range(max_length - 1):\n",
    "        next_words = bigram_model[current_word]\n",
    "        if not next_words:\n",
    "            break\n",
    "        current_word = random.choice(next_words) # choose the next word randomly\n",
    "        sentence.append(current_word)\n",
    "    \n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Step 3: Generate a sequence starting with 'the'\n",
    "generated_sentence = generate_sentence('the', max_length=10)\n",
    "print(generated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the above method simply counts the occurrences of word pair(bigrams) in the corpus and uses that to generate sequence\n",
    "- this type of model is based on frequency counts from the data rather than on learning parameters in a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Markov model trainable: turn into probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- meaning of trainable: learn from the data iteratively through optimization techniques\n",
    "- how to implement \"trainable\": the math that can take into account the situation of the dataset\n",
    "    - which means: probability\n",
    "- so markove model inlucde two parts:\n",
    "    1. initial state\n",
    "    2. transition matrix: reflect the situation of the dataset, such as the portion of \"the cat\" given \"the\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
